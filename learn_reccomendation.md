<!-- タイトル：kaggle Competitionの為にImplicit ALS base modelの概要を学ぶ１ -->

# はじめに
1年前にKaggleに登録しましたが、今回初Competitionとして、「H&M Personalized Fashion Recommendations」に参加してみようと思いました(1ヶ月おくれですが...笑)。
データセットはテーブルデータを基本としている為、画像データやテキストデータに疎い私の様な人にも比較的取っつきやすい気がします。
また、**最終的な成果物(提出物)が"顧客へのレコメンド"**という点がよりビジネス的というか、実務(?)に近いような気がする(私は学生なので偏見かもしれませんが...笑)ので、個人的に楽しみです：）


# レコメンデーションエンジンの実力を見る
テイラーとジェーンは二人とも映画を見るのが好きです。Taylorはドラマ、コメディ、ロマンスしか好みません。ジェーンは、アクションやアドベンチャーなど、刺激的な映画ばかりを好みます。**ALSを使ったレコメンデーションエンジンの最大のメリットは、ユーザー自身が「これは嫌いかもしれない」と思っている映画やアイテムでも、「これは好きそうだ」と判断できることです**。テイラーとジェーンの映画の評価を見てみましょう。二人の好みが違えば、推薦も違ってくるのは当然でしょう。

# レコメンドにおける2種類のデータ(explicitとimplicit)
レコメンドエンジンは通販サイトや、最近ではメディアを放送するWebサイト等でもよく見られます。
顧客の嗜好データ(好みのデータ)を元にしたレコメンドエンジンにおいて、活用できるデータは大きく以下の2種に分類できるようです。
- explicit(明示的)データ：
  - ユーザ自身が作成した各アイテムの**直接的な(明示的な)**評価データ.
  - ex. 星1~5の評価, Good or Badボタンなど、
- implicit(暗黙的)データ：
  - ユーザ行動の受動的な追跡に基づいて決められる、**間接的な**評価データ.
  - ex. クリックやサイト訪問、購入等の、**アクションの有無、または頻度**
  - 
- 
# 2種類のレコメンデーションエンジン
大きく2種類。どちらも有益なレコメントを提供する事を目的としているが、方法は少し異なる.
1. コンテンツベースのフィルタリングエンジン(Content-Based Filtering)
   - 名前通り"コンテンツ"を理解しようとする.
   - **アイテムの特徴に基づいて**レコメンドする.
     - ex.映画の例
       - ジャンル(コメディ、アクション、ドラマ)
       - アニメ or not
       - 言語(英語、日本語、etc.)
       - 公開された年代(1950's, 1980's)
       - 出演俳優
     - 上記のような特徴を示す"タグ"を作成しておく必要がある!
   - もしAさんがあるドラマ形式の日本映画に5つ星の評価を与えれば、レコメンドエンジンはAさんが"同様の特徴を持ったアイテムが好き"と判断し、似た特徴を持つアイテムをレコメンドする.
2. 強調フィルタリングエンジン(Collaborative Filtering)
   - **ユーザの類似性に基づいて**レコメンドする.
   - 手動で作成したタグは必要ない.
   - 類似性(グルーピング)は、ユーザが提供する評価のパターンから数学的に作成される.
   - ALSアルゴリズムは、explicitもしくはimplicitデータから数学的にユーザのグルーピングを作成できる.
     - ALSはコンテンツベースの手法でも利用される.
     - (強調フィルタリングの原則の多くは、コンテンツベースの手法に適用できる)


# ALSアルゴリズム（レコメンデーションエンジン）の応用例
- 潜在的な特徴の発見
  - 一部のアイテムは様々なカテゴリにまたがっており、グルーピングの整理が困難.
    - =>消費者がどのようにアイテム(映画など)を分類するかをより良く理解できれば、マーケティング戦略に更に力を加える事ができる.
    - =>ALSはコレを助ける事ができる.
  - ユーザ×アイテムの行列を、2つの行列に因数分解する.
    - ![](image_markdown\ALS因数分解.PNG)
    - 分解後の各カラムとレコードのラベルは以下のようになる.
      - ![](image_markdown\ALS因数分解2.PNG)
    - ラベルのない軸には、**潜在的特徴(Latest features)**が入る.
      - 潜在的特徴の数は、これらの行列の**ランク**と呼ばれる.この場合は3。
      - ランクは指定すべきハイパラ.
      - ![](image_markdown\ALS因数分解3.PNG)
      - **潜在的特徴は、元のパターンから作成されたグループ**を表す.(次元圧縮ってこうやってるのか...!)
      - 分解後の行列において、**潜在的特徴でない方の軸は、各アイテム(ユーザ)がこれらのグループにどの程度分類されるか**を表す.
  - アイテム側の行列の見方の例：
    - ![](image_markdown\ALS因数分解2.PNG)
    - 1つのレコードは、ホラー映画の値が高く、ドラマ映画の値は低い。
    - また他のレコードは、その逆。
    - **元々の行列の各映画(アイテム)の情報を少し知っていれば**、**分解後の潜在的特徴がこれら2つのジャンルを反映している**、と判断できる！
    - ＝＞これにより、**ユーザがこれらの映画(アイテム)をどのように分類するかを数学的に確認**できる!
- アイテムのグループ化
- 次元削減
- 画像圧縮
# おわりに

# 参考
以下の記事を参考にさせていただきました！良記事有り難うございます！
- https://www.kaggle.com/julian3833/h-m-implicit-als-model-0-014
- https://blog.uni-3.app/implicit-als
- https://campus.datacamp.com/courses/recommendation-engines-in-pyspark/what-if-you-dont-have-customer-ratings?ex=4
- Pyspark cheet sheet
  - https://datacamp-community-prod.s3.amazonaws.com/65076e3c-9df1-40d5-a0c2-36294d9a3ca9