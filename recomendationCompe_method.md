<!-- Winning the Netflix Prize: A Summary -->

# はじめに
ここでは、Netflix Prizeの受賞解法に込められたテクニックの概要

# Normalization of Global Effects
例えば、あるユーザ"アリスさん"が、あるアイテム"インセプション(映画名らしい...)"に対して"4つ星"で評価したとする。この評価はいくつかのPartから構成されていると見なす事ができる：
1. ベースラインの評価
   -  （例えば、すべてのユーザーと映画の評価の平均が3.1つ星である場合）
2. あるユーザ"アリスさん"特有の効果
   - (例えば、アリスは平均的なユーザーよりも映画を低く評価する傾向があるので、彼女の評価は通常予想されるよりも-0.5星低い)
3. あるアイテム"インセプション"特有の効果
   - （例えば、インセプションはかなり素晴らしい映画なので、その評価は私たちが通常期待するよりも0.7つ星高くなる）
4. ユーザ"アリスさん"とアイテム"インセプション"の間の特定の相互作用に基づく、より予測しづらい効果
   - （例えば、アリスはレオナルド・ディカプリオと神経科学の特別な組み合わせのためにインセプションを本当に気に入ったので、この評価はさらに0.7星になります）
   
- この考え方にしたがうと、"4つ星"の評価の内訳を分解する事ができる。
   - 4 = 3.1（ベースライン評価） - 0.5（ユーザ特有の効果） + 0.7（アイテム特有の効果）+ 0.7 (ユーザとアイテム間の特定の相互作用)
＝＞つまり、モデルに4つ星評価そのものを予測させるのではなく、まず**ベースライン予測因子(1~3の成分)の効果**を除去して、**"ユーザとアイテム間の特定の相互作用"を予測させる**様にすればいい！

より一般的には、以下の要素がベースライン予測因子に追加されうる：
- アリスの評価が、最初の評価からの日数（の平方根）に（線形に）依存するようにする要素。
- アリスの評価が、その映画が誰かによって最初に評価されてからの日数に依存するようにする要因。
- アリスの評価が、インセプションを評価した人の数に依存するような要因。
- アリスの評価が、その映画の全体的な評価に依存するような要因。
- (その他もろもろ)

そして実際、これらのBiasをモデル化する事はかなり重要である事が判明した。
Netflix Prizeの最終解を説明した論文の中で、ベルとコーンは次のように書いている。
- アルゴリズムによる数多くの新しい貢献の中で、私はその1つに注目したいと思います。それは、**データの主効果を捉える、地味なベースライン予測因子（またはバイアス）**です。この文献では、より洗練されたアルゴリズムの側面に焦点が当てられていますが、主効果を正確に扱うことは、おそらくモデリングのブレークスルーをもたらすことと同じくらい重要であることを私たちは学びました。
- (これらのバイアスを除去することがなぜ有用であるかのおそらくより具体的な例として、ボブがアリスと同じ種類の映画を好きであることを知っていると仮定します。インセプションのボブの評価を予測するために、アリスが評価したのと同じ4つの星を単純に予測するのではなく、ボブは映画を平均より0.3つ高く評価する傾向があると知っているなら、まずアリスのバイアスを取り除き、次にボブのバイアスを加えることができる。4 + 0.5 + 0.3 = 4.8.)

# Neighborhood Models
ここで、もう少し洗練されたモデルを見てみよう。上のセクションで言及したように、協調フィルタリングの標準的なアプローチの1つは、近傍モデルを使うことです。

簡単に言うと、近傍モデルは次のように動作します。アリスのタイタニックの評価を予測するために、2つのことをすることができます。
- Item-item approach
  - アリスが評価した"タイタニックに似たアイテムの集合"を見つけ、それに対するアリスの評価の（加重）平均を取る。
- User-user approach
  - アリスと同じユーザーの集合を見つけ、彼らのタイタニックに対する評価の平均を取る。
# Implicit Data
# Matrix Factorization
# Regression
# Restricted Boltzmann Machines
# Ensemble Methods

# おわりに